{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp39-cp39-win_amd64.whl (430.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/termcolor/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 462, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Anaconda3\\lib\\http\\client.py\", line 506, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 366, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 212, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 203, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp39-cp39-win_amd64.whl (895 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S-nk-MZiKDWE"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DPL_QS~1\\AppData\\Local\\Temp/ipykernel_20908/3722658931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kWiSNU8bO8Ee"
   },
   "outputs": [],
   "source": [
    "f0 = open(\"1661-0.txt\", \"r\")\n",
    "f1 = open('pg5200.txt', 'r')\n",
    "lines0 = [i for i in f0]\n",
    "lines1 = [i for i in f1]\n",
    "lines = lines0 + lines1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-2DBsXuPP5q",
    "outputId": "691089c3-0629-40f5-f72a-3834d03c0a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First Line:  Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
      "\n",
      "The Last Line:  subscribe to our email newsletter to hear about new eBooks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The First Line: \", lines[1])\n",
    "print(\"The Last Line: \", lines[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "wPztLm3Wz6IZ",
    "outputId": "1f25f94f-e2f5-468c-bb0e-6cfe420e9ff0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \"\"\n",
    "\n",
    "for i in lines:\n",
    "  words = ' '.join(c for c in lines if not c.isdigit()) # converting all the lines in the text files to a corpus or text document\n",
    "    \n",
    "words = words.replace('\\n', '').replace('\\ufeff', '').replace(\"\\\\\", '')\n",
    "words[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCtZDjhz0YSJ",
    "outputId": "cd280176-d3a0-42bb-f1c1-df8d6c4e6072"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136561"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer() #convert the words to a a sequences of integers\n",
    "tokenizer.fit_on_texts([words]) #fit on our corpus\n",
    "sequences = tokenizer.texts_to_sequences([words])[0]\n",
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tumIhzOz8qoH",
    "outputId": "602fc456-14f8-4984-999d-18aa96c76fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9648\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8KclYFw8VAk",
    "outputId": "c68df6fd-b32e-44bc-9fac-a9c2154c6773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 5442], [5442, 1], [1, 1215], [1215, 4], [4, 169], [169, 42]]\n"
     ]
    }
   ],
   "source": [
    "#we create training data based on each word in our array of sequences and the next word to follow\n",
    "training_data = []\n",
    "for i in range(1, len(sequences)):\n",
    "    training_data.append(sequences[i-1:i+1])\n",
    "print(training_data[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qNAOcy1ApsA",
    "outputId": "6f641968-2e16-417f-a7f1-a6abab5c86b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If X:101, then y:5442\n"
     ]
    }
   ],
   "source": [
    "X = np.array([i[0] for i in training_data])\n",
    "y = np.array([i[1] for i in training_data])\n",
    "print(f\"If X:{X[0]}, then y:{y[0]}\")\n",
    "y = keras.utils.to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkFUMGWVDhfE",
    "outputId": "739c4cfb-1661-41e0-8a5a-18c8aa3ca3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "325/325 [==============================] - 152s 461ms/step - loss: 6.7798 - accuracy: 0.0515 - val_loss: 6.8655 - val_accuracy: 0.0513\n",
      "Epoch 2/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 6.4210 - accuracy: 0.0516 - val_loss: 6.8643 - val_accuracy: 0.0513\n",
      "Epoch 3/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 6.2628 - accuracy: 0.0561 - val_loss: 6.4813 - val_accuracy: 0.0767\n",
      "Epoch 4/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 5.9526 - accuracy: 0.0807 - val_loss: 6.1818 - val_accuracy: 0.0986\n",
      "Epoch 5/50\n",
      "325/325 [==============================] - 149s 459ms/step - loss: 5.6526 - accuracy: 0.1070 - val_loss: 5.9670 - val_accuracy: 0.1258\n",
      "Epoch 6/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 5.4360 - accuracy: 0.1215 - val_loss: 5.8856 - val_accuracy: 0.1353\n",
      "Epoch 7/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 5.2875 - accuracy: 0.1299 - val_loss: 5.8208 - val_accuracy: 0.1434\n",
      "Epoch 8/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 5.1811 - accuracy: 0.1370 - val_loss: 5.8041 - val_accuracy: 0.1508\n",
      "Epoch 9/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 5.0967 - accuracy: 0.1431 - val_loss: 5.7877 - val_accuracy: 0.1539\n",
      "Epoch 10/50\n",
      "325/325 [==============================] - 148s 456ms/step - loss: 5.0231 - accuracy: 0.1486 - val_loss: 5.7783 - val_accuracy: 0.1580\n",
      "Epoch 11/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.9552 - accuracy: 0.1522 - val_loss: 5.7723 - val_accuracy: 0.1592\n",
      "Epoch 12/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.8921 - accuracy: 0.1558 - val_loss: 5.7801 - val_accuracy: 0.1629\n",
      "Epoch 13/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.8333 - accuracy: 0.1601 - val_loss: 5.7765 - val_accuracy: 0.1678\n",
      "Epoch 14/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.7779 - accuracy: 0.1627 - val_loss: 5.7943 - val_accuracy: 0.1674\n",
      "Epoch 15/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.7244 - accuracy: 0.1650 - val_loss: 5.7586 - val_accuracy: 0.1708\n",
      "Epoch 16/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.6759 - accuracy: 0.1681 - val_loss: 5.7910 - val_accuracy: 0.1734\n",
      "Epoch 17/50\n",
      "325/325 [==============================] - 149s 459ms/step - loss: 4.6292 - accuracy: 0.1693 - val_loss: 5.7880 - val_accuracy: 0.1779\n",
      "Epoch 18/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.5868 - accuracy: 0.1709 - val_loss: 5.8210 - val_accuracy: 0.1727\n",
      "Epoch 19/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.5434 - accuracy: 0.1731 - val_loss: 5.8273 - val_accuracy: 0.1779\n",
      "Epoch 20/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.5036 - accuracy: 0.1749 - val_loss: 5.8646 - val_accuracy: 0.1838\n",
      "Epoch 21/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.4661 - accuracy: 0.1765 - val_loss: 5.8814 - val_accuracy: 0.1863\n",
      "Epoch 22/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.4295 - accuracy: 0.1777 - val_loss: 5.8942 - val_accuracy: 0.1873\n",
      "Epoch 23/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.3964 - accuracy: 0.1787 - val_loss: 5.9447 - val_accuracy: 0.1838\n",
      "Epoch 24/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.3637 - accuracy: 0.1803 - val_loss: 5.9561 - val_accuracy: 0.1943\n",
      "Epoch 25/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.3341 - accuracy: 0.1820 - val_loss: 5.9947 - val_accuracy: 0.1880\n",
      "Epoch 26/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.3075 - accuracy: 0.1825 - val_loss: 5.9971 - val_accuracy: 0.1914\n",
      "Epoch 27/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.2820 - accuracy: 0.1836 - val_loss: 6.0373 - val_accuracy: 0.1984\n",
      "Epoch 28/50\n",
      "325/325 [==============================] - 148s 456ms/step - loss: 4.2598 - accuracy: 0.1849 - val_loss: 6.0565 - val_accuracy: 0.1967\n",
      "Epoch 29/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.2380 - accuracy: 0.1853 - val_loss: 6.1112 - val_accuracy: 0.1958\n",
      "Epoch 30/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.2182 - accuracy: 0.1860 - val_loss: 6.0937 - val_accuracy: 0.1929\n",
      "Epoch 31/50\n",
      "325/325 [==============================] - 148s 457ms/step - loss: 4.2000 - accuracy: 0.1866 - val_loss: 6.1339 - val_accuracy: 0.1960\n",
      "Epoch 32/50\n",
      "325/325 [==============================] - 148s 456ms/step - loss: 4.1842 - accuracy: 0.1866 - val_loss: 6.1835 - val_accuracy: 0.1952\n",
      "Epoch 33/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.1691 - accuracy: 0.1866 - val_loss: 6.1782 - val_accuracy: 0.1977\n",
      "Epoch 34/50\n",
      "325/325 [==============================] - 148s 456ms/step - loss: 4.1537 - accuracy: 0.1871 - val_loss: 6.1926 - val_accuracy: 0.1974\n",
      "Epoch 35/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.1414 - accuracy: 0.1875 - val_loss: 6.2359 - val_accuracy: 0.1970\n",
      "Epoch 36/50\n",
      "325/325 [==============================] - 149s 457ms/step - loss: 4.1284 - accuracy: 0.1876 - val_loss: 6.2424 - val_accuracy: 0.1926\n",
      "Epoch 37/50\n",
      "325/325 [==============================] - 150s 460ms/step - loss: 4.1157 - accuracy: 0.1865 - val_loss: 6.3093 - val_accuracy: 0.2002\n",
      "Epoch 38/50\n",
      "325/325 [==============================] - 149s 459ms/step - loss: 4.1051 - accuracy: 0.1882 - val_loss: 6.2867 - val_accuracy: 0.1946\n",
      "Epoch 39/50\n",
      "325/325 [==============================] - 149s 460ms/step - loss: 4.0945 - accuracy: 0.1879 - val_loss: 6.3374 - val_accuracy: 0.2008\n",
      "Epoch 40/50\n",
      "325/325 [==============================] - 149s 459ms/step - loss: 4.0855 - accuracy: 0.1874 - val_loss: 6.3106 - val_accuracy: 0.2004\n",
      "Epoch 41/50\n",
      "325/325 [==============================] - 150s 460ms/step - loss: 4.0757 - accuracy: 0.1880 - val_loss: 6.3701 - val_accuracy: 0.1935\n",
      "Epoch 42/50\n",
      "325/325 [==============================] - 149s 460ms/step - loss: 4.0672 - accuracy: 0.1884 - val_loss: 6.3858 - val_accuracy: 0.1945\n",
      "Epoch 43/50\n",
      "325/325 [==============================] - 149s 460ms/step - loss: 4.0584 - accuracy: 0.1880 - val_loss: 6.4035 - val_accuracy: 0.2034\n",
      "Epoch 44/50\n",
      "325/325 [==============================] - 150s 461ms/step - loss: 4.0501 - accuracy: 0.1882 - val_loss: 6.4478 - val_accuracy: 0.1983\n",
      "Epoch 45/50\n",
      "325/325 [==============================] - 150s 461ms/step - loss: 4.0417 - accuracy: 0.1883 - val_loss: 6.4716 - val_accuracy: 0.2059\n",
      "Epoch 46/50\n",
      "325/325 [==============================] - 150s 460ms/step - loss: 4.0349 - accuracy: 0.1880 - val_loss: 6.4819 - val_accuracy: 0.2001\n",
      "Epoch 47/50\n",
      "325/325 [==============================] - 149s 460ms/step - loss: 4.0279 - accuracy: 0.1875 - val_loss: 6.5184 - val_accuracy: 0.2005\n",
      "Epoch 48/50\n",
      "325/325 [==============================] - 150s 460ms/step - loss: 4.0213 - accuracy: 0.1880 - val_loss: 6.5197 - val_accuracy: 0.1960\n",
      "Epoch 49/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.0155 - accuracy: 0.1881 - val_loss: 6.5545 - val_accuracy: 0.2056\n",
      "Epoch 50/50\n",
      "325/325 [==============================] - 149s 458ms/step - loss: 4.0098 - accuracy: 0.1889 - val_loss: 6.4935 - val_accuracy: 0.2012\n"
     ]
    }
   ],
   "source": [
    "#Defining the model, a recurrent neural network\n",
    "next_words_model = keras.models.Sequential([\n",
    "                                            keras.layers.Embedding(vocab_size, 10, input_length=1),\n",
    "                                            keras.layers.LSTM(1000, return_sequences=True),\n",
    "                                            keras.layers.LSTM(1000),\n",
    "                                            keras.layers.Dense(500, activation = 'relu'),\n",
    "                                            keras.layers.Dense(vocab_size, activation = 'softmax')\n",
    "])\n",
    "next_words_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = next_words_model.fit(X, y, epochs=50, batch_size=128, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dMVEtPbEArt",
    "outputId": "61ad0287-900f-4bdf-91c1-baee5ffc9e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_tokenizer.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_model.save('next_words_model.h5')\n",
    "joblib.dump(tokenizer, 'text_tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "VxN8krBiB7of"
   },
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "\n",
    "model = keras.models.load_model('next_words_model.h5')\n",
    "tokenizer = joblib.load('text_tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "bUKAB4lZCbGe"
   },
   "outputs": [],
   "source": [
    "def retrain_model(text):\n",
    "  retrain_seq = tokenizer.texts_to_sequences([text])[0]\n",
    "  retrain_data = []\n",
    "  for i in range(1, len(retrain_seq)):\n",
    "    retrain_data.append(retrain_seq[i-1:i+1])\n",
    "  X_train = np.array([v[0] for v in retrain_data])\n",
    "  y_train = np.array([v[1] for v in retrain_data])\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes=vocab_size)\n",
    "  model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "nyDtQhecHAEd"
   },
   "outputs": [],
   "source": [
    "def predict_next_word(text):\n",
    "  try:\n",
    "    text = text.split(\" \")\n",
    "    text = text[-1]\n",
    "  \n",
    "  except:\n",
    "    print('Invalid Entry')\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "  sequence = np.array(sequence)\n",
    "\n",
    "  preds = model.predict(sequence)\n",
    "  pred_words = tokenizer.sequences_to_texts([sorted(np.argsort(preds)[0][-3:])]) #getting the words with the highest probabilities\n",
    "\n",
    "  pred_words = pred_words[0].split(' ')\n",
    "  print(\"The most probable word is: {} \\n Other likely words: {}, {}\".format(pred_words[0], pred_words[1], pred_words[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ATBLLZ_IJdC"
   },
   "outputs": [],
   "source": [
    "retrain_model('My hand hurts like hell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJWm3CDKVL1U",
    "outputId": "6dcf7e2a-e8d0-495e-cbf6-0c1dda01b919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probable word is: is \n",
      " Other likely words: lucy, hurts\n"
     ]
    }
   ],
   "source": [
    "predict_next_word('hand')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Next_word_predictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
